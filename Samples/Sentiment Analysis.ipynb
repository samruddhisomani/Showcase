{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import isnan\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.tokenizers import WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Assignment 3 Edmunds Posts.csv\", usecols=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Standardize multiple different ways of referring to the same car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Posts'] = data['Posts'].map(lambda x: x.replace(\"LexusES\",\"ES\"))\n",
    "data['Posts'] = data['Posts'].map(lambda x: x.replace(\"ES330\",\"ES\"))\n",
    "data['Posts'] = data['Posts'].map(lambda x: x.replace(\"LS460\",\"LS\"))\n",
    "data['Posts'] = data['Posts'].map(lambda x: x.replace(\"LS470\",\"LS\"))\n",
    "\n",
    "data['Posts'] = data['Posts'].map(lambda x: x.replace(\"LexusLS\",\"LS\"))\n",
    "data['Posts'] = data['Posts'].map(lambda x: x.replace(\"LexusRX\",\"RX\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Define necessary functions and lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sw=stopwords.words('english')\n",
    "\n",
    "sw.remove('not')\n",
    "\n",
    "models_skinny=[\"es\",\"ls\",\"rx\",\"a8\",\"a6\",\"3series\",\\\n",
    "               \"5series\",\"7series\",\"xj\",\"sclass\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokenize words, remove stop words, lemmatize remaining words, and return them in lowercase\n",
    "def tKnzr (xstring):\n",
    "    global sw\n",
    "    tokens=list(TextBlob(str(xstring)).words)\n",
    "    removeStopWords=[word for word in tokens if word.lower() not in sw]\n",
    "    lemmaed=[Word(w).lemmatize() for w in removeStopWords]\n",
    "    lowercase=[word.lower() for word in lemmaed]\n",
    "    return lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find words within a certain distance of models\n",
    "def finder (tokensList, modelList, numberWords):\n",
    "    blanklist=[]\n",
    "    for i in xrange(len(tokensList)):\n",
    "        if tokensList[i] in modelList:\n",
    "            blanklist.append(tokensList[i-numberWords:i+1+numberWords])\n",
    "    return blanklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile sentiments into a single analyzable dataframe\n",
    "def sentiment_compiler(postseries,modelsList,numberofwords):\n",
    "    tb=Blobber(tokenizer=WordTokenizer())\n",
    "    \n",
    "    newseries=postseries.apply(tKnzr)\n",
    "    newseries=newseries.apply(lambda x: finder(x,modelsList, numberofwords))\n",
    "    newseries=newseries.apply(lambda x: [' '.join(inner) for inner in x])\n",
    "    \n",
    "    models=[\" \"+x+\" \" for x in modelsList]\n",
    "    df=pd.DataFrame(columns=modelsList).join(newseries, how=\"outer\")\n",
    "    \n",
    "    for index,l in enumerate(newseries):\n",
    "        for string in l: #looping over all the strings in model_strings\n",
    "                for model, model_skinny in zip(models,modelsList): #loop over all the models in\nmodel list\n",
    "                    if model in string: #check if model is in a particular list\n",
    "                        if isnan(df[model_skinny].iloc[index]): #correcting for neutral\n",
    "                            df[model_skinny].iloc[index]=0\n",
    "                        df[model_skinny].iloc[index]+=tb(string).sentiment[0]  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Run functions on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q=sentiment_compiler(data['Posts'],models_skinny,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>es</th>\n",
       "      <th>ls</th>\n",
       "      <th>rx</th>\n",
       "      <th>a8</th>\n",
       "      <th>a6</th>\n",
       "      <th>3series</th>\n",
       "      <th>5series</th>\n",
       "      <th>7series</th>\n",
       "      <th>xj</th>\n",
       "      <th>sclass</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>[previous '01 sclass pre-'03 refresh, one issu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    es   ls   rx a8   a6 3series 5series 7series   xj    sclass  \\\n",
       "0  NaN  NaN  NaN  0  NaN     NaN     NaN     NaN  NaN -0.166667   \n",
       "\n",
       "                                               Posts  \n",
       "0  [previous '01 sclass pre-'03 refresh, one issu...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.head(1) #this review compares the s-class to the a8."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "notify_time": "0"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
